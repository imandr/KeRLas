{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from KeRLas import Brain, TimedGymEnv, Trainer\n",
    "from KeRLas.models import defaultQModel\n",
    "from KeRLas.models import DirectDiffModel, NaiveQModel, LateralDiffModel\n",
    "from KeRLas.policies import BoltzmannQPolicy\n",
    "import numpy as np\n",
    "import gym, math\n",
    "from cartpole import CartPoleEnv\n",
    "\n",
    "#env = GymEnv(CartPoleEnv(), tlimit=300)\n",
    "env = TimedGymEnv(CartPoleEnv(), tlimit=300)\n",
    "\n",
    "space = env.observation_space\n",
    "high = np.array(\n",
    "    [\n",
    "        2.4,\n",
    "        1.0,\n",
    "        12 * 2 * math.pi / 360,\n",
    "        1.0\n",
    "    ]\n",
    ")\n",
    "env.RandomObservationSpace = gym.spaces.Box(-high, high)\n",
    "\n",
    "observation_width = env.observation_space.shape[0]\n",
    "nactions = env.action_space.n\n",
    "\n",
    "\n",
    "#for i in range(10):\n",
    "#    next(brain.Memory.generate_samples(20))\n",
    "#_ = next(brain.trainig_data_generator(mbsize))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rlmodel = LateralDiffModel(defaultQModel(observation_width, nactions), 0.9, weight=1.0)\n",
    "policy = BoltzmannQPolicy(0.0001)\n",
    "brain = Brain(rlmodel, policy, training_policies=map(BoltzmannQPolicy, [10.0, 1.0, 0.1, 0.01, 0.001]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.2 0.025137765\n",
      "60.8 0.013347905\n",
      "48.4 0.01622584\n",
      "28.4 0.018314851\n",
      "69.4 0.017693035\n",
      "49.6 0.010159255\n"
     ]
    }
   ],
   "source": [
    "class Callback:\n",
    "    \n",
    "    def onEpisodeBegin(self, env, agents, observations):\n",
    "        env.render()\n",
    "\n",
    "    def onStep(self, env, env_done, feedback):\n",
    "        env.render()\n",
    "        \n",
    "    def onEpisodeEnd(self, env, record):\n",
    "        env.render()\n",
    "\n",
    "trainer = Trainer(env, brain, 0.5, 10000)   \n",
    "\n",
    "from KeRLas import GymPlayer\n",
    "p = GymPlayer(env, brain, callback=Callback())\n",
    "\n",
    "#temps = [10.0, 1.0, 0.1, 0.01, 0.001]\n",
    "\n",
    "mbsize = 50\n",
    "\n",
    "for i in xrange(20):\n",
    "    metrics = trainer.train(mbsize, 1000, 10)\n",
    "    \n",
    "    nsum = 0\n",
    "    N = 5\n",
    "    with brain.training(False):\n",
    "        for _ in range(N):\n",
    "            history = p.runEpisode()\n",
    "            #print len(history)\n",
    "            nsum += len(history)\n",
    "        print float(nsum)/N, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in xrange(100):\n",
    "    p.runEpisode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
